{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from os.path import exists\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import easygui\n",
    "import sys\n",
    "\n",
    "abay_station = {'SGN':'TP Hồ Chí Minh (SGN)', 'HAN':'Hà Nội (HAN)', 'DAD':'Đà Nẵng (DAD)', 'UIH':'Quy Nhơn (UIH)', 'PQC':'Phú Quốc (PQC)'}\n",
    "abay_routes = {'SGN':'Tp_Ho_Chi_Minh', 'HAN':'Ha_Noi', 'DAD':'Da_Nang', 'UIH':'Quy_Nhon', 'PQC':'Phu_Quoc'}\n",
    "\n",
    "# if scrapping_info not exists or null, tell user to input information\n",
    "if not exists('scrapping_info.xlsx'):\n",
    "    easygui.msgbox(\"Please input the scrapping_info\", title=\"Input alert\")\n",
    "    pd.DataFrame(columns=['from_date', 'to_date', 'route']).to_excel('scrapping_info.xlsx', index=False)\n",
    "    sys.exit()\n",
    "if pd.read_excel('scrapping_info.xlsx').shape[0] == 0:\n",
    "    easygui.msgbox(\"Please input the scrapping_info\", title=\"Input alert\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# define a function to create a list of day_sector to scrape\n",
    "# also make a needed directory\n",
    "def route_pricing(from_date, to_date, route:str, use_range:bool = False, scrape_range:int = 40):\n",
    "    \"\"\"Create abay_scrapping folder under current directory and sub-directory of routes inside \\n\n",
    "    create a table with {'date', 'sector', 'dep station', 'arr staion', 'directory to save csv files'} \\n\n",
    "    if use_range = True, use the scrape range of 40 days, scrape_range can be changed as wished\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # create a folder in current directory\n",
    "    parent_dir = os.getcwd() + '\\\\' + 'abay_scrapping'\n",
    "    try:\n",
    "        os.mkdir(parent_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    scrapping_dates = pd.date_range(start=from_date, end=to_date)\n",
    "\n",
    "    # create string name of folder container\n",
    "    dep1 = route[:3]\n",
    "    arr1 = route[4:7]\n",
    "    dep2 = arr1\n",
    "    arr2 = dep1\n",
    "    sector1 = dep1 + '-' + arr1\n",
    "    sector2 = dep2 + '-' + arr2\n",
    "    \n",
    "    # create directory\n",
    "    sub_dir1 = route[:7]\n",
    "    sub_dir2 = route[4:]\n",
    "    dir_1 = os.path.join(parent_dir, sub_dir1)\n",
    "    dir_2 = os.path.join(parent_dir, sub_dir2)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_1)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_2)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # create a dataframe\n",
    "    to_scrape1 = pd.DataFrame({'dates':scrapping_dates, 'sector':sector1, 'dep':dep1, 'arr':arr1})\n",
    "    to_scrape1['dir'] = dir_1\n",
    "    to_scrape2 = pd.DataFrame({'dates':scrapping_dates, 'sector':sector2, 'dep':dep2, 'arr':arr2})\n",
    "    to_scrape2['dir'] = dir_2\n",
    "    to_scrape = pd.concat([to_scrape1, to_scrape2])\n",
    "    to_scrape.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # flattern and return into a list\n",
    "    return to_scrape\n",
    "\n",
    "\n",
    "# define web scrapping function\n",
    "def abay_scrapping(ngay, thang, nam, dep_station, arr_station, location):\n",
    "    driver.get('https://www.abay.vn')\n",
    "    # choose the route\n",
    "    driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtFrom\").setAttribute('value', '{abay_station[dep_station]}');''')\n",
    "    driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtTo\").setAttribute('value', '{abay_station[arr_station]}');''')\n",
    "\n",
    "    # select day\n",
    "    dep_day = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureDay\"]'))\n",
    "    dep_day.select_by_value(str(ngay))\n",
    "    # select month\n",
    "    dep_month = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureMonth\"]'))\n",
    "    dep_month.select_by_value(f'{str(thang).zfill(2)}/{nam}')\n",
    "    # click the button\n",
    "    search_button = driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_btnSearch\"]')\n",
    "    search_button.click()\n",
    "    \n",
    "\n",
    "    time.sleep(1)\n",
    "    # scrape information\n",
    "    flights_table = driver.find_element(By.XPATH, '//table[@class=\"f-result\"]')\n",
    "    flight_rows = flights_table.find_elements(By.XPATH, '//tr[@class=\"i-result\"]')\n",
    "\n",
    "    f_name = []\n",
    "    f_time = []\n",
    "    f_baggage_meal = []\n",
    "    f_price = []\n",
    "    final_baggage_meal = []\n",
    "\n",
    "    for row in flight_rows:\n",
    "        f_name.append(row.find_element(By.XPATH, './td[2]').text)\n",
    "        f_time.append(row.find_element(By.XPATH, './td[3]').text)\n",
    "        f_baggage_meal.append(row.find_element(By.XPATH, './td[4]').find_elements(By.TAG_NAME, 'img'))\n",
    "        f_price.append(row.find_element(By.XPATH, './td[5]').text)\n",
    "\n",
    "    for bag_meal in f_baggage_meal:\n",
    "        tmp_str = ''\n",
    "        for element in bag_meal:\n",
    "            tmp_str += '-' + element.get_attribute('src').split('/')[-1]\n",
    "        final_baggage_meal.append(tmp_str)\n",
    "\n",
    "    f_date = [f'{nam}-{thang}-{ngay}'] * len(f_name)\n",
    "\n",
    "    df = pd.DataFrame({'name': f_name, 'time': f_time, 'baggage_meal': final_baggage_meal, 'price': f_price, 'date' : f_date})\n",
    "    df['price'] = df['price'].str[:-1]\n",
    "\n",
    "    df['bag'] = df['baggage_meal'].str.contains('hanhly')*1\n",
    "    df['meal'] = df['baggage_meal'].str.contains('suatan')*1\n",
    "    column_order = ['name', 'time', 'bag', 'meal', 'price', 'date']\n",
    "    df = df.reindex(columns=column_order)\n",
    "    \n",
    "    csv_path = f'{location}\\\\Abay_scrapping_price_{dep_station}-{arr_station}_{nam}{str(thang).zfill(2)}{ngay}.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define a function to apply on a dataframe\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "\n",
    "# pd.DataFrame(err_list, columns=['date', 'sector', 'dir']).to_excel('error_list.xlsx', index=False)\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_date</th>\n",
       "      <th>to_date</th>\n",
       "      <th>route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>SGN-UIH-SGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from_date    to_date        route\n",
       "0 2022-10-05 2022-10-05  SGN-UIH-SGN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapping_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "to_scrape_all = []\n",
    "def route_pricing_apply(row):\n",
    "    to_scrape_all.append(route_pricing(from_date=row['from_date'], to_date=row['to_date'], route=row['route']))\n",
    "\n",
    "scrapping_info = pd.read_excel('scrapping_info.xlsx')\n",
    "scrapping_info.apply(route_pricing_apply, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape_all = pd.concat(to_scrape_all).drop_duplicates().values.tolist()\n",
    "\n",
    "err_list = []\n",
    "for scrape in to_scrape_all:\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            err_list.append(scrape)\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping(ngay=scrape[0].day, thang=scrape[0].month, nam=scrape[0].year, dep_station=scrape[2], arr_station=scrape[3])\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VTA_RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9e384aec62ae57b5f76b26318facd26f7d8e2315f3809fc741dc47f714fdba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
