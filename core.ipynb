{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e2b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from datetime import date\n",
    "from datetime import datetime\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get('https://www.abay.vn')\n",
    "while True:\n",
    "    try:\n",
    "        search_button = driver.find_element(By.ID, 'cphMain_ctl00_usrSearchFormD2_btnSearch')\n",
    "        search_button.click()\n",
    "        break\n",
    "    except: pass\n",
    "\n",
    "# define scrapping function\n",
    "\n",
    "abay_routes = {'SGN':'Tp_Ho_Chi_Minh', 'HAN':'Ha_Noi', 'DAD':'Da_Nang', 'UIH':'Quy_Nhon', 'PQC':'Phu_Quoc'}\n",
    "# abay_station = {'SGN':'TP Hồ Chí Minh (SGN)', 'HAN':'Hà Nội (HAN)', 'DAD':'Đà Nẵng (DAD)', 'UIH':'Quy Nhơn (UIH)', 'PQC':'Phú Quốc (PQC)', 'BKK':'Bangkok (BKK)'}\n",
    "abay_station = {'SGN':'SGN', 'HAN':'HAN', 'DAD':'DAD', 'UIH':'UIH', 'PQC':'PQC', 'BKK':'BKK', 'CXR':'CXR'}\n",
    "\n",
    "def create_dir(route:str):\n",
    "    sub_dir1 = route[:7]\n",
    "    sub_dir2 = route[4:]\n",
    "\n",
    "    parent_dir = r'C:\\Users\\VTA-HAN\\Desktop\\VTA Jupyter\\webscrapping'\n",
    "    dir_1 = os.path.join(parent_dir, sub_dir1)\n",
    "    dir_2 = os.path.join(parent_dir, sub_dir2)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(dir_1)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_2)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    return [dir_1, dir_2]\n",
    "\n",
    "\n",
    "def route_pricing(from_date:str, to_date:str, route:str, parent_dir:str = r'C:\\Users\\VTA-HAN\\Desktop\\VTA Jupyter\\webscrapping'):\n",
    "    input_format_date = '%Y%m%d'\n",
    "    from_date = datetime.strptime(from_date, input_format_date)\n",
    "    to_date = datetime.strptime(to_date, input_format_date)\n",
    "    scrapping_dates = pd.date_range(start=from_date, end=to_date)\n",
    "    \n",
    "    dep1 = route[:3]\n",
    "    arr1 = route[4:7]\n",
    "    dep2 = arr1\n",
    "    arr2 = dep1\n",
    "\n",
    "    \n",
    "#     define and create directory\n",
    "    sub_dir1 = route[:7]\n",
    "    sub_dir2 = route[4:]\n",
    "    dir_1 = os.path.join(parent_dir, sub_dir1)\n",
    "    dir_2 = os.path.join(parent_dir, sub_dir2)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_1)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_2)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "#     create a dataframe\n",
    "    to_scrape1 = pd.DataFrame({'dates':scrapping_dates, 'dep':dep1, 'arr':arr1})\n",
    "    to_scrape1['dir'] = dir_1\n",
    "    to_scrape2 = pd.DataFrame({'dates':scrapping_dates, 'dep':dep2, 'arr':arr2})\n",
    "    to_scrape2['dir'] = dir_2\n",
    "    \n",
    "    to_scrape = pd.concat([to_scrape1, to_scrape2])\n",
    "    to_scrape.sort_values(by='dates', ascending=True, inplace=True)\n",
    "\n",
    "#     flattern and return into a list\n",
    "    return to_scrape.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990f9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abay_scrapping_domestic(ngay, thang, nam, dep_station, arr_station, location):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # dep_station\n",
    "            input_element = driver.find_element(By.ID, 'hdfstartplace')\n",
    "            driver.execute_script(f\"arguments[0].value = '{abay_station[dep_station]}';\", input_element)\n",
    "\n",
    "            # arr_station\n",
    "            input_element = driver.find_element(By.ID, 'hdfendplace')\n",
    "            driver.execute_script(f\"arguments[0].value = '{abay_station[arr_station]}';\", input_element)\n",
    "\n",
    "            # choose departure date\n",
    "            dep_date = driver.find_element(By.XPATH, '//*[@id=\"cphSubColumn_ctl01_txtDepartureDate\"]')\n",
    "            driver.execute_script(f\"arguments[0].value = '{str(ngay).zfill(2)}/{str(thang).zfill(2)}/{nam}';\", dep_date)\n",
    "\n",
    "\n",
    "            # click the search button\n",
    "            search_button = driver.find_element(By.ID, 'cphSubColumn_ctl01_btnSearchFlight')\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scroll windows to the end of page\n",
    "            search_button.click()\n",
    "            break\n",
    "        except: pass\n",
    "\n",
    "\n",
    "\n",
    "    # scrape information\n",
    "    while True:\n",
    "        try:\n",
    "            flights_table = driver.find_element(By.XPATH, '//*[@id=\"OutBound\"]')\n",
    "            flight_rows = flights_table.find_elements(By.XPATH, '//tr[@class=\"i-result\"]')\n",
    "            \n",
    "            f_name = []\n",
    "            f_time = []\n",
    "            f_baggage_meal = []\n",
    "            f_price = []\n",
    "            final_baggage_meal = []\n",
    "\n",
    "            for row in flight_rows:\n",
    "                f_name.append(row.find_element(By.XPATH, './td[2]').text)\n",
    "                f_time.append(row.find_element(By.XPATH, './td[3]').text)\n",
    "                f_baggage_meal.append(row.find_element(By.XPATH, './td[4]').find_elements(By.TAG_NAME, 'img'))\n",
    "                f_price.append(row.find_element(By.XPATH, './td[5]').text)\n",
    "\n",
    "            for bag_meal in f_baggage_meal:\n",
    "                tmp_str = ''\n",
    "                for element in bag_meal:\n",
    "                    tmp_str += '-' + element.get_attribute('src').split('/')[-1]\n",
    "                final_baggage_meal.append(tmp_str)\n",
    "\n",
    "            f_date = [f'{nam}-{thang}-{ngay}'] * len(f_name)\n",
    "\n",
    "            df = pd.DataFrame({'name': f_name, 'time': f_time, 'baggage_meal': final_baggage_meal, 'price': f_price, 'date' : f_date})\n",
    "            df['price'] = df['price'].str[:-1]\n",
    "\n",
    "            df['bag'] = df['baggage_meal'].str.contains('hanhly')*1\n",
    "            df['meal'] = df['baggage_meal'].str.contains('suatan')*1\n",
    "            column_order = ['name', 'time', 'bag', 'meal', 'price', 'date']\n",
    "            df = df.reindex(columns=column_order)\n",
    "\n",
    "            csv_path = f'{location}\\\\Abay_scrapping_price_{dep_station}-{arr_station}_{nam}{str(thang).zfill(2)}{str(ngay).zfill(2)}.csv'\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            break\n",
    "        except: pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def abay_scrapping_international(ngay, thang, nam, dep_station, arr_station, location):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # dep_station\n",
    "            input_element = driver.find_element(By.ID, 'hdfstartplace')\n",
    "            driver.execute_script(f\"arguments[0].value = '{abay_station[dep_station]}';\", input_element)\n",
    "\n",
    "            # arr_station\n",
    "            input_element = driver.find_element(By.ID, 'hdfendplace')\n",
    "            driver.execute_script(f\"arguments[0].value = '{abay_station[arr_station]}';\", input_element)\n",
    "\n",
    "            # choose departure date\n",
    "            dep_date = driver.find_element(By.XPATH, '//*[@id=\"cphSubColumn_ctl01_txtDepartureDate\"]')\n",
    "            driver.execute_script(f\"arguments[0].value = '{str(ngay).zfill(2)}/{str(thang).zfill(2)}/{nam}';\", dep_date)\n",
    "\n",
    "\n",
    "            # click the search button\n",
    "            search_button = driver.find_element(By.ID, 'cphSubColumn_ctl01_btnSearchFlight')\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scroll windows to the end of page\n",
    "            search_button.click()\n",
    "            break\n",
    "        except: pass\n",
    "\n",
    "\n",
    "\n",
    "    # wait untill all flights are available\n",
    "    while True:\n",
    "        try: \n",
    "            if driver.find_element(By.XPATH, f'//*[@id=\"main\"]/section[3]/div[1]').get_attribute('class') == 'captions-container':\n",
    "                break\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "    # get the data\n",
    "    i = 2\n",
    "    name = []\n",
    "    dep_time = []\n",
    "    stop_point = []\n",
    "    price_adt = []\n",
    "\n",
    "    while True:\n",
    "        try: flight = driver.find_element(By.XPATH, f'//*[@id=\"main\"]/section[3]/div[{i}]')\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        name.append(driver.find_element(By.XPATH, f'//*[@id=\"main\"]/section[3]/div[{i}]/div[2]/div/ul[4]/li[2]/code').get_attribute(\"textContent\"))\n",
    "        dep_time.append(flight.find_element(By.XPATH, './/div[1]/ul/li/div[2]/strong[1]').text)\n",
    "        stop_point.append(flight.get_attribute('data-stop-points'))\n",
    "        price_adt.append(flight.get_attribute('data-base-price-adt'))\n",
    "        i += 1\n",
    "\n",
    "    # cast into a dataframe\n",
    "    df = pd.DataFrame({'name':name,'time': dep_time,'bag':0,'meal':0,'stop_point': stop_point,'price': price_adt, 'date':f'{nam}-{thang}-{ngay}'})\n",
    "    df['time'] = df['time'].str.replace('|', '', regex=False)\n",
    "    df['time'] = df['time'] + ' - ' + df['time']\n",
    "    df['stop_point'] = df['stop_point'].str.replace('|', '', regex=False)\n",
    "    df = df[df['stop_point'] == '0']\n",
    "    df = df[['name', 'time', 'bag', 'meal', 'price', 'date']]\n",
    "\n",
    "    # CSV exporting\n",
    "    csv_path = f'{location}\\\\Abay_scrapping_price_{dep_station}-{arr_station}_{nam}{str(thang).zfill(2)}{str(ngay).zfill(2)}.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c2be0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGN-UIH-SGN: 100%|█████████████████████████████████████████████████████████████████████| 84/84 [02:07<00:00,  1.52s/it]\n",
      "SGN-PQC-SGN: 100%|█████████████████████████████████████████████████████████████████████| 84/84 [03:58<00:00,  2.84s/it]\n",
      "SGN-DAD-SGN: 100%|█████████████████████████████████████████████████████████████████████| 84/84 [04:18<00:00,  3.08s/it]\n",
      "HAN-CXR-HAN: 100%|█████████████████████████████████████████████████████████████████████| 84/84 [03:23<00:00,  2.42s/it]\n",
      "err_list: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "err_list = []\n",
    "for x in tqdm(route_pricing('20230620', '20230731', 'SGN-UIH-SGN'), desc='SGN-UIH-SGN'):\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            err_list.append([x[0].day, x[0].month, x[0].year, x[1], x[2], x[3]])\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping_domestic(x[0].day, x[0].month, x[0].year, x[1], x[2], x[3])\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "        \n",
    "for x in tqdm(route_pricing('20230620', '20230731', 'SGN-PQC-SGN'), desc='SGN-PQC-SGN'):\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            err_list.append([x[0].day, x[0].month, x[0].year, x[1], x[2], x[3]])\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping_domestic(x[0].day, x[0].month, x[0].year, x[1], x[2], x[3])\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "        \n",
    "for x in tqdm(route_pricing('20230620', '20230731', 'SGN-DAD-SGN'), desc='SGN-DAD-SGN'):\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            err_list.append([x[0].day, x[0].month, x[0].year, x[1], x[2], x[3]])\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping_domestic(x[0].day, x[0].month, x[0].year, x[1], x[2], x[3])\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "for x in tqdm(route_pricing('20230620', '20230731', 'HAN-CXR-HAN'), desc='HAN-CXR-HAN'):\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            err_list.append([x[0].day, x[0].month, x[0].year, x[1], x[2], x[3]])\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping_domestic(x[0].day, x[0].month, x[0].year, x[1], x[2], x[3])\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "        \n",
    "err_list2 = []\n",
    "for x in tqdm(err_list, desc='err_list'):\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            err_list2.append([x[0], x[1], x[2], x[3], x[4], x[5]])\n",
    "            break\n",
    "        try:\n",
    "            abay_scrapping_domestic(x[0], x[1], x[2], x[3], x[4], x[5])\n",
    "        except:\n",
    "            continue\n",
    "        break       \n",
    "        \n",
    "print(err_list2)\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6adb8717c4d0a5bbc833609db47a0d4a022aa11119d5859c7607f3701f1e243a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
