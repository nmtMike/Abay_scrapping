{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "abay_station = {'SGN':'TP Hồ Chí Minh (SGN)', 'HAN':'Hà Nội (HAN)', 'DAD':'Đà Nẵng (DAD)', 'UIH':'Quy Nhơn (UIH)', 'PQC':'Phú Quốc (PQC)'}\n",
    "abay_routes = {'SGN':'Tp_Ho_Chi_Minh', 'HAN':'Ha_Noi', 'DAD':'Da_Nang', 'UIH':'Quy_Nhon', 'PQC':'Phu_Quoc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abay_scrapping(ngay, thang, nam, dep, arr, location):\n",
    "    driver.get('https://www.abay.vn')\n",
    "    \n",
    "    # choose the route\n",
    "    driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtFrom\").setAttribute('value', '{abay_station[dep]}');''')\n",
    "    driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtTo\").setAttribute('value', '{abay_station[arr]}');''')\n",
    "\n",
    "    # select day\n",
    "    dep_day = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureDay\"]'))\n",
    "    dep_day.select_by_value(str(ngay))\n",
    "    # select month\n",
    "    dep_month = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureMonth\"]'))\n",
    "    dep_month.select_by_value(f'{str(thang).zfill(2)}/{nam}')\n",
    "    # click the button\n",
    "    search_button = driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_btnSearch\"]')\n",
    "    search_button.click()\n",
    "    \n",
    "\n",
    "    time.sleep(2)\n",
    "    # scrape information\n",
    "    flights_table = driver.find_element(By.XPATH, '//table[@class=\"f-result\"]')\n",
    "    flight_rows = flights_table.find_elements(By.XPATH, '//tr[@class=\"i-result\"]')\n",
    "\n",
    "    f_name = []\n",
    "    f_time = []\n",
    "    f_baggage_meal = []\n",
    "    f_price = []\n",
    "    final_baggage_meal = []\n",
    "\n",
    "    for row in flight_rows:\n",
    "        baggage_meal = []\n",
    "        f_name.append(row.find_element(By.XPATH, './td[2]').text)\n",
    "        f_time.append(row.find_element(By.XPATH, './td[3]').text)\n",
    "        f_baggage_meal.append(row.find_element(By.XPATH, './td[4]').find_elements(By.TAG_NAME, 'img'))\n",
    "        f_price.append(row.find_element(By.XPATH, './td[5]').text)\n",
    "\n",
    "    for bag_meal in f_baggage_meal:\n",
    "        tmp_str = ''\n",
    "        for element in bag_meal:\n",
    "            tmp_str += '-' + element.get_attribute('src').split('/')[-1]\n",
    "        final_baggage_meal.append(tmp_str)\n",
    "\n",
    "    f_date = [f'{nam}-{thang}-{ngay}'] * len(f_name)\n",
    "\n",
    "    df = pd.DataFrame({'name': f_name, 'time': f_time, 'baggage_meal': final_baggage_meal, 'price': f_price, 'date' : f_date})\n",
    "    df['price'] = df['price'].str[:-1]\n",
    "\n",
    "    df['bag'] = df['baggage_meal'].str.contains('hanhly')*1\n",
    "    df['meal'] = df['baggage_meal'].str.contains('suatan')*1\n",
    "    column_order = ['name', 'time', 'bag', 'meal', 'price', 'date']\n",
    "    df = df.reindex(columns=column_order)\n",
    "    \n",
    "    \n",
    "    if ngay < 10:\n",
    "        ngay = '0' + str(ngay)\n",
    "    if thang < 10:\n",
    "        thang = '0' + str(thang)\n",
    "\n",
    "    # csv_path = str(location) + r'\\price' + str(ten) + str(nam) + str(thang) + str(ngay) + '.csv'\n",
    "    csv_path = f'{location}_price_{dep}-{arr}_{nam}{str(thang).zfill(2)}{ngay}.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_pricing(from_date:str, to_date:str, route:str, use_range:bool = False, scrape_range:int = 40):\n",
    "    \"\"\"Create abay_scrapping folder under current directory and sub-directory of routes inside \\n\n",
    "    create a table with {'date', 'sector', 'dep station', 'arr staion', 'directory to save csv files'} \\n\n",
    "    if use_range = True, use the scrape range of 40 days, scrape_range can be changed as wished\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # create a folder in current directory\n",
    "    parent_dir = os.getcwd() + '\\\\' + 'abay_scrapping'\n",
    "    try:\n",
    "        os.mkdir(parent_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    scrapping_dates = pd.date_range(start=from_date, end=to_date)\n",
    "\n",
    "    # create string name of folder container\n",
    "    dep1 = route[:3]\n",
    "    arr1 = route[4:7]\n",
    "    dep2 = arr1\n",
    "    arr2 = dep1\n",
    "    sector1 = dep1 + '-' + arr1\n",
    "    sector2 = dep2 + '-' + arr2\n",
    "    \n",
    "    # create directory\n",
    "    sub_dir1 = route[:7]\n",
    "    sub_dir2 = route[4:]\n",
    "    dir_1 = os.path.join(parent_dir, sub_dir1)\n",
    "    dir_2 = os.path.join(parent_dir, sub_dir2)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_1)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir_2)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # create a dataframe\n",
    "    to_scrape1 = pd.DataFrame({'dates':scrapping_dates, 'sector':sector1, 'dep':dep1, 'arr':arr1})\n",
    "    to_scrape1['dir'] = dir_1\n",
    "    to_scrape2 = pd.DataFrame({'dates':scrapping_dates, 'sector':sector2, 'dep':dep2, 'arr':arr2})\n",
    "    to_scrape2['dir'] = dir_2\n",
    "    to_scrape = pd.concat([to_scrape1, to_scrape2])\n",
    "    to_scrape.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # flattern and return into a list\n",
    "    return to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "abay_scrapping(10, 10, 2022, 'SGN', 'UIH', r'C:\\Users\\admin\\Desktop\\VTA\\Abay_scrapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngay = 10\n",
    "thang = 10\n",
    "nam = 2022\n",
    "dep = 'SGN'\n",
    "arr = 'UIH'\n",
    "location = r'C:\\Users\\admin\\Desktop\\VTA\\Abay_scrapping'\n",
    "driver.get('https://www.abay.vn')\n",
    "    \n",
    "# choose the route\n",
    "driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtFrom\").setAttribute('value', '{abay_station[dep]}');''')\n",
    "driver.execute_script(f'''document.getElementById(\"cphMain_ctl00_usrSearchFormDV2_txtTo\").setAttribute('value', '{abay_station[arr]}');''')\n",
    "\n",
    "# select day\n",
    "dep_day = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureDay\"]'))\n",
    "dep_day.select_by_value(str(ngay))\n",
    "# select month\n",
    "dep_month = Select(driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_cboDepartureMonth\"]'))\n",
    "dep_month.select_by_value(f'{str(thang).zfill(2)}/{nam}')\n",
    "# click the button\n",
    "search_button = driver.find_element(By.XPATH, '//*[@id=\"cphMain_ctl00_usrSearchFormDV2_btnSearch\"]')\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "# scrape information\n",
    "flights_table = driver.find_element(By.XPATH, '//table[@class=\"f-result\"]')\n",
    "flight_rows = flights_table.find_elements(By.XPATH, '//tr[@class=\"i-result\"]')\n",
    "\n",
    "f_name = []\n",
    "f_time = []\n",
    "f_baggage_meal = []\n",
    "f_price = []\n",
    "final_baggage_meal = []\n",
    "\n",
    "for row in flight_rows:\n",
    "    baggage_meal = []\n",
    "    f_name.append(row.find_element(By.XPATH, './td[2]').text)\n",
    "    f_time.append(row.find_element(By.XPATH, './td[3]').text)\n",
    "    f_baggage_meal.append(row.find_element(By.XPATH, './td[4]').find_elements(By.TAG_NAME, 'img'))\n",
    "    f_price.append(row.find_element(By.XPATH, './td[5]').text)\n",
    "\n",
    "for bag_meal in f_baggage_meal:\n",
    "    tmp_str = ''\n",
    "    for element in bag_meal:\n",
    "        tmp_str += '-' + element.get_attribute('src').split('/')[-1]\n",
    "    final_baggage_meal.append(tmp_str)\n",
    "\n",
    "f_date = [f'{nam}-{thang}-{ngay}'] * len(f_name)\n",
    "\n",
    "df = pd.DataFrame({'name': f_name, 'time': f_time, 'baggage_meal': final_baggage_meal, 'price': f_price, 'date' : f_date})\n",
    "df['price'] = df['price'].str[:-1]\n",
    "\n",
    "df['bag'] = df['baggage_meal'].str.contains('hanhly')*1\n",
    "df['meal'] = df['baggage_meal'].str.contains('suatan')*1\n",
    "column_order = ['name', 'time', 'bag', 'meal', 'price', 'date']\n",
    "df = df.reindex(columns=column_order)\n",
    "\n",
    "\n",
    "if ngay < 10:\n",
    "    ngay = '0' + str(ngay)\n",
    "if thang < 10:\n",
    "    thang = '0' + str(thang)\n",
    "\n",
    "# csv_path = str(location) + r'\\price' + str(ten) + str(nam) + str(thang) + str(ngay) + '.csv'\n",
    "csv_path = f'{location}\\\\Abay_scrapping_price_{dep}-{arr}_{nam}{str(thang).zfill(2)}{ngay}.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Desktop\\\\VTA\\\\Abay_scrapping_price_SGN-UIH_20221010.csv'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VTA_RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9e384aec62ae57b5f76b26318facd26f7d8e2315f3809fc741dc47f714fdba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
